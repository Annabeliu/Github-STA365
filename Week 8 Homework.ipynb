{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8c9c89df",
   "metadata": {},
   "source": [
    "# Homework 8: (a) Posterior Predictive Distributions<br> and (b) Missing Data Imputation\n",
    "\n",
    "### 1. Describe how the posterior predictive distribution is created for mixture models \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7913f45a",
   "metadata": {},
   "source": [
    "We start by defining prior distributions for the parameters of the mixture models, which include parameters for the individual models being mixed as well as the probabilities for selecting each model. After observing the data and conducting Bayesian inference, we obtain posterior samples of these parameters. Utilizing these samples, we compute the posterior probabilities (weights) for each model/component within the mixture. Subsequently, we combine the component distributions, weighting them according to their posterior probabilities. Finally, we sum these weighted distributions to derive the posterior predictive distribution for the mixture model. This distribution offers insights into the distribution of future data points or unobserved data, amalgamating both prior beliefs and observed data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0e71b7e",
   "metadata": {},
   "source": [
    "### 2. Describe how the posterior predictive distribution is created in general"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44c06a1a",
   "metadata": {},
   "source": [
    "We begin by specifying prior distributions for the parameters of the mixed model. Bayesian inference is performed using observed data to obtain the posterior distribution of model parameters. This involves updating the prior beliefs based on the observed data, resulting in the posterior distribution, which represents our updated understanding of the parameters.Samples are drawn from the posterior distribution of model parameters using techniques such as Markov Chain Monte Carlo. These samples represent plausible values of the parameters given the observed data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93778126",
   "metadata": {},
   "source": [
    "### 3. Have glance through [this](https://www.pymc.io/projects/examples/en/latest/howto/Missing_Data_Imputation.html) and then describe how, if you were doing a regression of $y$ on $X$ but $X$ had some missing values, you could perform a Bayesian analysis without throwing away the rows with missing values in $X$\n",
    "\n",
    "- **Hint: latent variables $v$ indicating the subpopulation are competely missing values that we simply treat as paramters to be inferred though posterior analysis... the same sort of thing can be done with missing values in data that need to be imputed... we should just be careful about the MCAR assumption...**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b08e5ed",
   "metadata": {},
   "source": [
    "There are 3 type of missing data: Missing Completely at Random (MCAR), Missing at Random (MAR), and Missing Not at Random (MNAR). \n",
    "\n",
    "In a Bayesian framework, missing values can be imputed using latent variables $\\nu$. We can introduce $\\nu$ to represent the missing data and treat them as parameters to be inferred through posterior analysis. This approach allows us to model the uncertainty associated with missing values while incorporating them into the analysis. If the missingness is MCAR or MAR, we can include the latent variables  $\\nu$ in the model and specify appropriate priors. \n",
    "\n",
    "For MNAR, additional caution is needed, as the reasons for missingness are related to unobserved factors. In such cases, sensitivity analyses or robustness checks may be necessary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8876178e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
